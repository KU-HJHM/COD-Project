{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmyq/m94sJ/CSvmJMdwDgG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KU-HJHM/COD-Project/blob/main/%EC%83%81%EC%84%9C%EA%B3%A0%ED%9B%88_XML_%ED%8C%8C%EC%8B%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMCfmsAy51bO"
      },
      "outputs": [],
      "source": [
        "# 필요 패키지 설치(mpire)\n",
        "!pip install -U mpire\n",
        "\n",
        "# 필요 모듈 설치(pandas, numpy, lxml 등)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lxml\n",
        "# import xml.etree.ElementTree as ET\n",
        "import lxml.etree as et\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from natsort import natsorted\n",
        "import glob\n",
        "import multiprocessing\n",
        "from mpire import WorkerPool\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 불러오기\n",
        "!git clone https://github.com/KU-HJHM/COD-Project\n",
        "SSGH_YJ = \"/content/COD-Project/상서고훈_250411.xml\"\n",
        "tree = et.parse(SSGH_YJ)\n",
        "parser=et.XMLParser(encoding='utf-8')\n",
        "root = tree.getroot()"
      ],
      "metadata": {
        "id": "Gby4QTOC53YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###원문요소 Node 파싱(Volume)"
      ],
      "metadata": {
        "id": "pT02DS-N6f1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(element):\n",
        "    text_parts = []\n",
        "    if element.text:\n",
        "        text_parts.append(element.text.strip())\n",
        "    for child in element:\n",
        "        if child.tail:\n",
        "            text_parts.append(child.tail.strip())\n",
        "    return ''.join(text_parts)\n",
        "\n",
        "Volume_data = root.findall(\".//Volume\")\n",
        "Volume_data_list = []\n",
        "\n",
        "for Volume in Volume_data:\n",
        "  Volume_id = Volume.get(\"id\")\n",
        "  Volume_name = Volume.get(\"name\")\n",
        "  Volume_text = extract_text(Volume)\n",
        "  Volume_data_list.append({\"id\": Volume_id, \"name\": Volume_name, \"text\": Volume_text})\n",
        "df = pd.DataFrame(Volume_data_list)\n",
        "df.to_excel(\"volume_data.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "890QNZAl54PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###원문요소 Node 파싱(Paragraph)"
      ],
      "metadata": {
        "id": "pONtQEOK63Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(element):\n",
        "    text_parts = []\n",
        "    if element.text:\n",
        "        text_parts.append(element.text.strip())\n",
        "    for child in element:\n",
        "        if child.tail:\n",
        "            text_parts.append(child.tail.strip())\n",
        "    return ''.join(text_parts)\n",
        "\n",
        "Chapter_data = root.findall(\".//Chapter\")\n",
        "Chapter_data_list = []\n",
        "for Chapter in Chapter_data:\n",
        "  Chapter_id = Chapter.get(\"id\")\n",
        "  Chapter_name = Chapter.get(\"name\")\n",
        "  Chapter_text = extract_text(Chapter)\n",
        "  Chapter_data_list.append({\"id\": Chapter_id, \"name\": Chapter_name, \"text\": Chapter_text})\n",
        "df = pd.DataFrame(Chapter_data_list)\n",
        "df.to_excel(\"chapter_data.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "TywI6gY554wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###원문요소 Node 파싱(Paragraph)"
      ],
      "metadata": {
        "id": "D7xHiJdR67oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(element):\n",
        "    text_parts = []\n",
        "    if element.text:\n",
        "        text_parts.append(element.text.strip())\n",
        "    for child in element:\n",
        "        if child.tail:\n",
        "            text_parts.append(child.tail.strip())\n",
        "    return ''.join(text_parts)\n",
        "\n",
        "Paragraph_data = root.findall(\".//Paragraph\")\n",
        "Paragraph_data_list = []\n",
        "\n",
        "for Paragraph in Paragraph_data:\n",
        "  Paragraph_id = Paragraph.get(\"id\")\n",
        "  Paragraph_name = Paragraph.get(\"name\")\n",
        "  Paragraph_text = extract_text(Paragraph)\n",
        "  Paragraph_data_list.append({\"id\": Paragraph_id, \"name\": Paragraph_name, \"text\": Paragraph_text})\n",
        "df = pd.DataFrame(Paragraph_data_list)\n",
        "df.to_excel(\"paragraph_data.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "SUjMdtgE6onJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###원문요소 Node 파싱(구-Line)"
      ],
      "metadata": {
        "id": "GrtoE8-Z6_Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(element):\n",
        "    text_parts = []\n",
        "    if element.text:\n",
        "        text_parts.append(element.text.strip())\n",
        "    for child in element:\n",
        "        if child.tail:\n",
        "            text_parts.append(child.tail.strip())\n",
        "    return ''.join(text_parts)\n",
        "\n",
        "Line_data = root.findall(\".//Line\")\n",
        "Line_data_list = []\n",
        "\n",
        "for Line in Line_data:\n",
        "  Line_id = Line.get(\"id\")\n",
        "  Line_name = Line.get(\"name\")\n",
        "  Line_text = extract_text(Line)\n",
        "  Line_data_list.append({\"id\": Line_id, \"name\": Line_name, \"text\": Line_text})\n",
        "df = pd.DataFrame(Line_data_list)\n",
        "df.to_excel(\"line_data.xlsx\", index=False)\n"
      ],
      "metadata": {
        "id": "thyMNwLF6ohH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###원문요소 Node 파싱(Unit)"
      ],
      "metadata": {
        "id": "VuCEkvp-7OgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(element):\n",
        "    text_parts = []\n",
        "    if element.text:\n",
        "        text_parts.append(element.text.strip())\n",
        "    for child in element:\n",
        "        if child.tail:\n",
        "            text_parts.append(child.tail.strip())\n",
        "    return ''.join(text_parts)\n",
        "\n",
        "Unit_data = root.findall(\".//Unit\")\n",
        "Unit_data_list = []\n",
        "for Unit in Unit_data:\n",
        "  Unit_id = Unit.get(\"id\")\n",
        "  Unit_name = Unit.get(\"name\")\n",
        "  Unit_content = Unit.get(\"content\")\n",
        "  Unit_data_list.append({\"id\": Unit_id, \"name\": Unit_name, \"text\": Unit_content})\n",
        "df = pd.DataFrame(Unit_data_list)\n",
        "df.to_excel(\"unit_data.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "Xg8swhE-7N5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###주석요소 Node 파싱(Citation)"
      ],
      "metadata": {
        "id": "uRuOvXdo7HzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(element):\n",
        "    text_values = []\n",
        "    if element.text:\n",
        "        text_values.append(element.text.strip())\n",
        "    for child in element:\n",
        "        text_values.extend(extract_text(child))\n",
        "    if element.tail:\n",
        "        text_values.append(element.tail.strip())\n",
        "    return text_values\n",
        "\n",
        "Citation_data = root.findall(\".//Citation\")\n",
        "Citation_data_list = []\n",
        "\n",
        "for Citation in Citation_data:\n",
        "  Citation_id = Citation.get(\"id\")\n",
        "  Citation_name = Citation.get(\"name\")\n",
        "\n",
        "  #area 값 추출\n",
        "  if Citation_name and \"_\" in Citation_name:\n",
        "    area_part = Citation_name.split(\"_\")[1]\n",
        "    area = area_part[:2]\n",
        "  else:\n",
        "    area = None\n",
        "\n",
        "  #form 값 추출\n",
        "  parent = Citation.xpath(\"ancestor::SCommentary\")\n",
        "  if parent:\n",
        "    form = \"소주\"\n",
        "  else:\n",
        "    form = \"기본\"\n",
        "\n",
        "  #text 값 추출\n",
        "  text_values = extract_text(Citation)\n",
        "\n",
        "  Citation_data_list.append({\"id\": Citation_id, \"name\": Citation_name, \"area\": area, \"form\": form, \"text\": \" \".join(text_values)}) #Join the text elements and used a string literal\n",
        "df = pd.DataFrame(Citation_data_list)\n",
        "df.to_excel(\"citation_data.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "iWVCtuJG6oa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###주석요소 Node 파싱(Opinion)"
      ],
      "metadata": {
        "id": "NZtGbclY8Doy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(element):\n",
        "    text_values = []\n",
        "    if element.text:\n",
        "        text_values.append(element.text.strip())\n",
        "    for child in element:\n",
        "        text_values.extend(extract_text(child))\n",
        "    if element.tail:\n",
        "        text_values.append(element.tail.strip())\n",
        "    return text_values\n",
        "\n",
        "Opinion_data = root.findall(\".//Opin\")\n",
        "Opinion_data_list = []\n",
        "\n",
        "for Opinion in Opinion_data:\n",
        "  Opinion_id = Opinion.get(\"id\")\n",
        "  Opinion_name = Opinion.get(\"name\")\n",
        "\n",
        "  #area 값 추출\n",
        "  if Opinion_name and \"_\" in Opinion_name:\n",
        "    area_part = Opinion_name.split(\"_\")[1]\n",
        "    area = area_part[:2]\n",
        "  else:\n",
        "    area = None\n",
        "\n",
        "  #text 값 추출\n",
        "  text_values = extract_text(Opinion)\n",
        "  original_text = \" \".join(text_values)\n",
        "\n",
        "  Opinion_data_list.append({\"id\": Opinion_id, \"name\": Opinion_name, \"area\": area, \"text\": \" \".join(text_values)}) #Join the text elements and used a string literal\n",
        "df = pd.DataFrame(Opinion_data_list)\n",
        "df.to_excel(\"opinion_data.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "VAHtcrli8DUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###주석요소 Node 파싱(Remark)"
      ],
      "metadata": {
        "id": "VoB0rjRe9teg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(element):\n",
        "    text_values = []\n",
        "    if element.text:\n",
        "        text_values.append(element.text.strip())\n",
        "    for child in element:\n",
        "        text_values.extend(extract_text(child))\n",
        "    if element.tail:\n",
        "        text_values.append(element.tail.strip())\n",
        "    return text_values\n",
        "\n",
        "Opinion_data = root.findall(\".//Opin\")\n",
        "Opinion_data_list = []\n",
        "\n",
        "Remark_data = root.findall(\".//Remark\")\n",
        "Remark_data_list = []\n",
        "\n",
        "for Remark in Remark_data:\n",
        "  Remark_id = Remark.get(\"id\")\n",
        "  Remark_name = Remark.get(\"name\")\n",
        "\n",
        "  #area 값 추출\n",
        "  if Remark_name and \"_\" in Remark_name:\n",
        "    area_part = Remark_name.split(\"_\")[1]\n",
        "    area = area_part[:2]\n",
        "  else:\n",
        "    area = None\n",
        "\n",
        "  #text 값 추출\n",
        "  text_values = extract_text(Remark)\n",
        "  original_text = \" \".join(text_values)\n",
        "\n",
        "  Remark_data_list.append({\"id\": Remark_id, \"name\": Remark_name, \"area\": area, \"text\": \" \".join(text_values)}) #Join the text elements and used a string literal\n",
        "df = pd.DataFrame(Remark_data_list)\n",
        "df.to_excel(\"remark_data.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "03gp0la_6oPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###주석요소 Node 파싱(Mention)"
      ],
      "metadata": {
        "id": "Om691sCx9v79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Mention_data = root.findall(\".//Mention\")\n",
        "Mention_data_list = []\n",
        "\n",
        "for Mention in Mention_data:\n",
        "  Mention_id = Mention.get(\"id\")\n",
        "  Mention_name = Mention.get(\"name\")\n",
        "\n",
        "  #area 값 추출\n",
        "  if Mention_name and \"_\" in Mention_name:\n",
        "    area_part = Mention_name.split(\"_\")[1]\n",
        "    area = area_part[:2]\n",
        "  else:\n",
        "    area = None\n",
        "\n",
        "  #text 값 추출\n",
        "  text_values = extract_text(Mention)\n",
        "  original_text = \" \".join(text_values)\n",
        "\n",
        "  Mention_data_list.append({\"id\": Mention_id, \"name\": Mention_name, \"area\": area, \"text\": \" \".join(text_values)}) #Join the text elements and used a string literal\n",
        "df = pd.DataFrame(Mention_data_list)\n",
        "df.to_excel(\"mention_data.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "IW4Qac5-8pCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###주석요소 Node 파싱(Text)"
      ],
      "metadata": {
        "id": "H8r2HgAM-nDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Text_data = root.findall(\".//Text\")\n",
        "Text_data_list = []\n",
        "\n",
        "for Text in Text_data:\n",
        "  Text_id = Text.get(\"id\")\n",
        "  Text_name = Text.get(\"name\")\n",
        "\n",
        "  #text 값 추출\n",
        "  text_values = extract_text(Text)\n",
        "  original_text = \" \".join(text_values)\n",
        "\n",
        "  # reference 값 추출\n",
        "  Refer = Text.find(\"./../Refer\")  # 현재 Text 태그의 부모 태그에서 Refer 탐색\n",
        "  reference_values = []\n",
        "  referencetype_values = []\n",
        "  if Refer is not None:\n",
        "    for tag in [\"Book\", \"Part\", \"Person\"]:  # Book, Part, Person 태그 탐색\n",
        "      elements = Refer.findall(f\".//{tag}\")\n",
        "      for element in elements:\n",
        "        if element.text:\n",
        "          reference_values.append(element.text.strip())\n",
        "          referencetype_values.append(tag)\n",
        "\n",
        "  reference = \" \".join(reference_values)  # 공백으로 연결해 하나의 문자열로 처리\n",
        "  referencetype = \" \".join(referencetype_values)\n",
        "\n",
        "  Text_data_list.append({\"id\": Text_id, \"name\": Text_name, \"text\": original_text, \"reference\": reference, \"referencetype\": referencetype}) #Join the text elements and used a string literal\n",
        "df = pd.DataFrame(Text_data_list)\n",
        "df.to_excel(\"text_data.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "U3A8GBkF8o_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###문맥요소 Node 파싱(Book)"
      ],
      "metadata": {
        "id": "mV8trQMs-Pgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Book_data = root.findall(\".//Book\")\n",
        "Book_data_list = []\n",
        "\n",
        "unique_books = {}\n",
        "\n",
        "for Book in Book_data:\n",
        "    Book_id = Book.get(\"id\")\n",
        "    Book_korname = Book.get(\"korname\")\n",
        "    Book_chiname = Book.get(\"chiname\")\n",
        "\n",
        "    # id, korname, chiname이 모두 있을 때만 저장\n",
        "    if Book_id and Book_korname and Book_chiname:\n",
        "        unique_books[Book_id] = {\"id\": Book_id, \"korname\": Book_korname, \"chiname\": Book_chiname}\n",
        "\n",
        "# 중복 제거된 결과를 리스트로 변환 (id 기준)\n",
        "final_book_data_list = list(unique_books.values())\n",
        "\n",
        "# DataFrame으로 변환 후 저장\n",
        "df_book = pd.DataFrame(final_book_data_list)\n",
        "df_book.to_excel(\"book_data.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "I-ReoZoN8o8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###문맥요소 Node 파싱(Person)"
      ],
      "metadata": {
        "id": "Ry6PL5kA-yas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Person_data = root.findall(\".//Person\")\n",
        "unique_person = {}\n",
        "\n",
        "for Person in Person_data:\n",
        "    Person_id = Person.get(\"id\")\n",
        "    Person_korname = Person.get(\"korname\")\n",
        "    Person_chiname = Person.get(\"chiname\")\n",
        "\n",
        "    # id, korname, chiname이 모두 있을 때만 저장\n",
        "    if Person_id and Person_korname and Person_chiname:\n",
        "        unique_person[Person_id] = {\n",
        "            \"id\": Person_id,\n",
        "            \"korname\": Person_korname,\n",
        "            \"chiname\": Person_chiname\n",
        "        }\n",
        "\n",
        "# 중복 제거된 결과를 리스트로 변환\n",
        "final_person_data_list = list(unique_person.values())\n",
        "\n",
        "# DataFrame으로 변환 후 저장\n",
        "df_person = pd.DataFrame(final_person_data_list)\n",
        "df_person.to_excel(\"person_data.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "5CYgF_ch8o3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gKTo2gJn-2pW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_i0k_nKx-2in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xXJveOdD-2aA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}